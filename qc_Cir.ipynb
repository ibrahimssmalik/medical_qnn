{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for data analysis and imaging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset\n",
    "train_path = r\"path\\C-NMC\\training_data\\fold_0\"\n",
    "val_path = r\"path\\C-NMC\\validation_data\"\n",
    "test_path = r\"path\\C-NMC\\testing_data\\C-NMC_test_final_phase_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for deep learning and image manipulation\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard shape of image\n",
    "image_shape = (450,450,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # to train in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up generator for image manipulation to add diversity in dataset\n",
    "image_gen = ImageDataGenerator(rotation_range=20, # rotate 20 degrees\n",
    "                               width_shift_range=0.10, # shift width by max of 5%\n",
    "                               height_shift_range=0.10, # shift height by max of 5%\n",
    "                               rescale=1/255, # rescale image by normalzing\n",
    "                               shear_range=0.1, # cutting part of image (max 10%)\n",
    "                               zoom_range=0.1, # zoom by 10% max\n",
    "                               horizontal_flip=True, # horizontal flip\n",
    "                               fill_mode='nearest' # fill missing pixels with nearest filled value\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3527 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generator to get train images from directory and manipulate\n",
    "train_image_gen = image_gen.flow_from_directory(train_path,\n",
    "                                               target_size=image_shape[:2],\n",
    "                                                color_mode='rgb',\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1867 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generator to get validation images from directory and manipulate\n",
    "val_image_gen = image_gen.flow_from_directory(val_path,\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               color_mode='rgb',\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='binary',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shape: (16, 450, 450, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = next(train_image_gen) # extract one batch\n",
    "x_test, y_test = next(val_image_gen)\n",
    "\n",
    "print(f\"Train batch shape: {x_train.shape}\") # (batch_size, 8, 8, 3) for RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened shape: (16, 202500)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.mean(x_train, axis=-1).reshape(batch_size, -1) # convert to grayscale & flatten\n",
    "x_test = np.mean(x_test, axis=-1).reshape(batch_size, -1)\n",
    "\n",
    "print(f\"Flattened shape: {x_train.shape}\") # (batch_size, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for quantum computing\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits to match number of pixels in 8x8 image\n",
    "num_qubits = 16  \n",
    "\n",
    "# initialize quantum device simulator with 16 qubits\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "def encode_image(image):\n",
    "    \"\"\"Quantum circuit to encode image data\"\"\"\n",
    "    for i in range(num_qubits):\n",
    "        # apply a rotation around Y-axis on each qubit\n",
    "        # angle of rotation is proportional to pixel intensity (scaled by pi)\n",
    "        qml.RY(image[i] * np.pi, wires=i)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_circuit(image):\n",
    "    # encode image into quantum state using parameterized rotations\n",
    "    encode_image(image)\n",
    "    \n",
    "    # measure expectation value of the Pauli-Z operator for each qubit\n",
    "    # gives value between -1 and 1, representing qubit's state along Z-axis\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(num_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum features shape: (16, 16)\n"
     ]
    }
   ],
   "source": [
    "# apply quantum circuit to each image in training set\n",
    "# transforms classical image data into quantum feature representations\n",
    "x_train_q = np.array([quantum_circuit(img) for img in x_train])\n",
    "\n",
    "# apply same quantum transformation to test set\n",
    "x_test_q = np.array([quantum_circuit(img) for img in x_test])\n",
    "\n",
    "# print shape of resulting quantum feature vectors\n",
    "# each image is now represented by vector of expectation values (one per qubit)\n",
    "print(f\"Quantum features shape: {x_train_q.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_circuit(params, image):\n",
    "    # encode classical image into quantum states using RY rotations\n",
    "    encode_image(image)\n",
    "    \n",
    "    # apply trainable RY rotations to each qubit\n",
    "    for i in range(num_qubits):\n",
    "        qml.RY(params[i], wires=i)\n",
    "    \n",
    "    # measure expectation value of Pauli-Z operator on first qubit - serves as output of qnn\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnn(params, image):\n",
    "    # wrap variational circuit in QNode for execution\n",
    "    return variational_circuit(params, image)\n",
    "\n",
    "def quantum_model(params, images):\n",
    "    # apply qnn to batch of images\n",
    "    return np.array([qnn(params, img) for img in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for classical optimization routine\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params):\n",
    "    # generate predictions from quantum model\n",
    "    predictions = quantum_model(params, x_train_q)\n",
    "    \n",
    "    # compute mean squared error between predictions and true labels\n",
    "    return np.mean((predictions - y_train) ** 2)\n",
    "\n",
    "# initialize parameters randomly from normal distribution - one parameter per qubit for variational layer\n",
    "params = np.random.randn(num_qubits)\n",
    "\n",
    "# use BFGS optimization algorithm to minimize cost function\n",
    "opt_result = minimize(cost, params, method=\"BFGS\")\n",
    "\n",
    "# extract optimized parameters after training\n",
    "trained_params = opt_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use trained quantum model to make predictions on test set\n",
    "y_pred_q = np.round(quantum_model(trained_params, x_test_q))\n",
    "\n",
    "# calculate accuracy by comparing predicted labels to true labels\n",
    "accuracy = np.mean(y_pred_q == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quantum Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
